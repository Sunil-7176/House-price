{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Project Description**:\n",
        "\n",
        "The goal of this project is to predict house price based on real estate features extracted for houses in Bengaluru. The major sequence of steps in the coding process are listed below:\n",
        "\n",
        "1.   Load and clean up the data.\n",
        "2.   Analyze the features (*ordinal, categorical*, and *continuous*) for missingness, correct data type association, and distribution.\n",
        "3.   Spit the data into train and test sets..\n",
        "4.   Build an ML pipeline (*encoder -> imputer -> regression module*) for the train set by specifying seperate encoding and imputing steps (if needed) for ordinal, categorical, and continuous features.\n",
        "5.   Train the ML pipeline on the train set and apply it for prediction on the test set.\n",
        "6.   Report performance metrics"
      ],
      "metadata": {
        "id": "CDu-8IqkYWBu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Import libraries\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "X8dZYSUNSz3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline\n",
        "\n",
        "## Pipeline module\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "## Scaling, encoding, and imputation libraries\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import SimpleImputer, IterativeImputer\n",
        "\n",
        "# Column trandformation library\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "## Train-test, cross-validation, and grid search modules\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Cross-validation and grid search modules\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, cross_val_score\n",
        "\n",
        "## Regression modules\n",
        "from sklearn import linear_model\n",
        "\n",
        "## Performance metrics modules\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "hlm9I_zaS3yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Mount Google Drive if running in Colab\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hAR_5NRyS7vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Mount Google drive folder if running in Colab\n",
        "if('google.colab' in sys.modules):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount = True)\n",
        "    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/EvenSem2024MAHE'\n",
        "    DATA_DIR = DIR + '/Data/'\n",
        "    os.chdir(DIR)\n",
        "else:\n",
        "    DATA_DIR = 'Data/'"
      ],
      "metadata": {
        "id": "l5SiOb2OS-eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Load bengaluru house price data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "9FPkLtSaXfkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Load Bengaluru house price data\n",
        "file = DATA_DIR+'houseprices.csv'\n",
        "df= pd.read_csv(file, header = 0)\n",
        "\n",
        "print('Bengaluru house price dataset')\n",
        "print('-----------')\n",
        "print('Initial number of samples = %d'%(df.shape[0]))\n",
        "print('Initial number of features = %d\\n'%(df.shape[1]))\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "-9h-n1ndXioQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Clean up data\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "kh6EfFzhYFV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Clean up data\n",
        "# Remove 'title' column\n",
        "df.drop(?, axis = ?, inplace = True)\n",
        "\n",
        "# Retain only numerical values in area column\n",
        "df['area'] = df[?].apply(lambda x:float(x.split(' ')[0].replace(',', '')))\n",
        "\n",
        "# Retain only numerical values in rent column\n",
        "def rent_column_modify(val):\n",
        "  if 'Lacs' in val:\n",
        "    return(float(val.split(' ')[0].split('/')[0].replace(',', ''))*1e5)\n",
        "  else:\n",
        "    return(float(val.split('/')[0].replace(',', '')))\n",
        "df['rent'] = df['rent'].apply(?)\n",
        "\n",
        "# Retain only numerical values in the price_per_sqft column\n",
        "df[?] = df[?].apply(lambda x:float(?))\n",
        "\n",
        "# Retain onlt numerical values in BHK columns\n",
        "df[?] = df[?].apply(lambda x: int(?))\n",
        "\n",
        "# Change 'Don't Know' entries in 'facing' column to NaN\n",
        "df['facing'] = df['facing'].apply(lambda x: x if x != \"?\" else ?)\n",
        "\n",
        "# Change 'None' entries in 'parking' column to Nan\n",
        "df['parking'] = df['parking'].apply(lambda x: ?)\n",
        "\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "Iw1iq4oQYH0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Plot percentage of missing values (NaNs) for each feature\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6k4npZ0XFlpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Plot percentage of missing values (NaNs) for each feature\n",
        "cutoff = 10 # we will remove features missing in more than cutoff% of the samples\n",
        "fig = plt.figure(figsize=(4, 4))\n",
        "percent_missing = (df.?().sum() / df.shape[?]) * 100\n",
        "percent_missing.plot(kind = 'bar', color = cm.rainbow(np.linspace(0, 1, 2))[(percent_missing <= cutoff).values.astype(int)])\n",
        "plt.plot(np.arange(df.shape[1]), np.repeat(cutoff, df.shape[1]), 'g--')\n",
        "fig.suptitle('Percentage Missing Values Across All Features', fontsize = 10)\n",
        "plt.xlabel('Feature', fontsize = 8)\n",
        "plt.ylabel('% Missing Values', fontsize = 8);"
      ],
      "metadata": {
        "id": "yXisytC6Fj9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Create lists of ordinal, categorical, and continuous features\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "2zD6chdEHfWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create lists of ordinal, categorical, and continuous features\n",
        "ordinal_features = [?, ?]\n",
        "categorical_features = [?, ?, ?]\n",
        "continuous_features = (df.drop(?, axis = 1)).drop(?, axis = 1).columns.tolist()"
      ],
      "metadata": {
        "id": "PLKUpPV-HdyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Assign 'category' datatype to ordinal and categorical columns\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "IO0VqHgXIqiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Assign 'category' datatype to ordinal and categorical columns\n",
        "print(df.dtypes)\n",
        "df[ordinal_features + categorical_features] = df[? + ?].astype(?)\n",
        "print('----')\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "cB1ZL1BVIpBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Print unique values in each ordinal and categorical features\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HCvU-GzoJNcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Print unique values in each ordinal and categorical features\n",
        "print(df[ordinal_features + categorical_features].nunique())\n",
        "print('\\nUnique values in ordinal and categorical features')\n",
        "print('---------------------------------------------------')\n",
        "unique_values = {col:list(df[?].unique()) for col in ? + ?}\n",
        "for key, value in ?.items():\n",
        "  print(key, ?)"
      ],
      "metadata": {
        "id": "IHR5cD5NJMQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Remove the target variable column from the list of continuous features\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HR46WIh4KPMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Remove the target variable column from the list of continuous features\n",
        "continuous_features.remove(?)"
      ],
      "metadata": {
        "id": "MNqqqWU-J0ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Plot the distributions of the features\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "A8a9FPtBa3oy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JRareCODa7Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Train-test split of the dataset\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "8YOoSGUhKSAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Train and test split of the data\n",
        "X = df.drop('price_per_sqft', axis = ?)\n",
        "y = ?\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ?,\n",
        "                                                    test_size = 0.1,\n",
        "                                                    random_state = 1)\n",
        "print('# training samples = %d, # test samples = %d'%(X_train.shape[?], ?))"
      ],
      "metadata": {
        "id": "E-_sG79VKMTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Build pipeline for ordinal, categorical, and continuous features\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "9iJ3fjvlRUYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Build pipeline for ordinal, categorical, and continuous features\n",
        "\n",
        "# Pipeline object for ordinal features\n",
        "ordinal_transformer = Pipeline(steps = [('ordinalenc', OrdinalEncoder())])\n",
        "\n",
        "# Pipeline object for categorical (features\n",
        "categorical_transformer = Pipeline(steps = [('imputer', SimpleImputer(missing_values = ?, strategy = ?)), ('onehotenc', ?(handle_unknown = 'ignore'))])\n",
        "\n",
        "# Pipeline object for continuous features\n",
        "continuous_transformer = Pipeline(steps = [('scaler', ?)])\n",
        "\n",
        "# Create a preprocessor object for all features\n",
        "preprocessor = ColumnTransformer(transformers = [('continuous', continuous_transformer, continuous_features),\n",
        "                                                 ('categorical', categorical_transformer, categorical_features),\n",
        "                                                 ('ordinal', ordinal_transformer, ordinal_features)\n",
        "                                                ],\n",
        "                                 remainder = 'passthrough'\n",
        "                                 )\n",
        "\n",
        "# Define a classifier object\n",
        "regressor = linear_model.LinearRegression()\n",
        "\n",
        "# Define the entire classification model pipeline\n",
        "model_pipeline = Pipeline(steps = [('preprocessor', ?), ('regressor', ?)])"
      ],
      "metadata": {
        "id": "LupJp1f5Rbcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "Fit the pipeline on the train data and test on the test data\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "1aS_hLbcVIZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Fit the model pipeline on the train data and test on the test data\n",
        "model_pipeline.fit(?, ?)\n",
        "y_pred = model_pipeline.?(X_test)\n",
        "print('Mean Squared Error : {}'.format(mean_squared_error(?, ?)))\n",
        "print('r2_score : {}'.format(?(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "2_VzFnI2VHJe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}